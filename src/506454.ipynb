{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import permutations, combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **1)** Five layer perceptron regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the data into a pandas DataFrame, and get a scikit-learn compatible dataset. Use\n",
    "the “target” column as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "full_data_part1 = pd.read_csv(\"Part 1.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Using only half of the data\n",
    "partial_data = full_data_part1.head(int(full_data_part1.shape[0]/2))\n",
    "\n",
    "features = [x for x in partial_data.columns.drop(\"target\")]\n",
    "\n",
    "X = partial_data[features]\n",
    "y = partial_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314826</td>\n",
       "      <td>0.876050</td>\n",
       "      <td>-0.685288</td>\n",
       "      <td>0.604524</td>\n",
       "      <td>-0.868619</td>\n",
       "      <td>-0.671283</td>\n",
       "      <td>-59.177636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662332</td>\n",
       "      <td>0.745420</td>\n",
       "      <td>-0.423713</td>\n",
       "      <td>0.179228</td>\n",
       "      <td>-1.349615</td>\n",
       "      <td>0.355827</td>\n",
       "      <td>-11.643998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.448170</td>\n",
       "      <td>0.065115</td>\n",
       "      <td>0.107046</td>\n",
       "      <td>0.459968</td>\n",
       "      <td>1.302039</td>\n",
       "      <td>-0.758131</td>\n",
       "      <td>35.562439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.199397</td>\n",
       "      <td>-1.109276</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.916933</td>\n",
       "      <td>-0.325098</td>\n",
       "      <td>-0.655460</td>\n",
       "      <td>-18.147836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.066389</td>\n",
       "      <td>1.762515</td>\n",
       "      <td>0.560241</td>\n",
       "      <td>-1.308726</td>\n",
       "      <td>-0.631064</td>\n",
       "      <td>-0.038181</td>\n",
       "      <td>-42.328718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_0    feat_1    feat_2    feat_3    feat_4    feat_5     target\n",
       "0  0.314826  0.876050 -0.685288  0.604524 -0.868619 -0.671283 -59.177636\n",
       "1  0.662332  0.745420 -0.423713  0.179228 -1.349615  0.355827 -11.643998\n",
       "2 -0.448170  0.065115  0.107046  0.459968  1.302039 -0.758131  35.562439\n",
       "3  1.199397 -1.109276 -0.003139 -0.916933 -0.325098 -0.655460 -18.147836\n",
       "4 -0.066389  1.762515  0.560241 -1.308726 -0.631064 -0.038181 -42.328718"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make a 70%/30% split of the dataset for training and testing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de treino: (3500, 6)\n",
      "Tamanho de teste: (1500, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print(f\"Tamanho de treino: {X_train.shape}\")\n",
    "print(f\"Tamanho de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using numpy, create a scikit-learn regressor that implements a multilayer perceptron\n",
    "architecture with 5 hidden layers.\n",
    "- The dimensionality of each layer is your decision.\n",
    "- Each hidden layer must have a bias unit.\n",
    "- All activations should be the sigmoid function.\n",
    "- You must use the backpropagation algorithm to calculate the derivatives.\n",
    "- Use mini-batch gradient descent to update the weights.\n",
    "- The parameters of the estimator are the following:\n",
    "    - **learning_rate:** A float number that determines the learning rate used for\n",
    "updating the weights on the update step of the gradient descent.\n",
    "    - **batch_size**: An integer that determines the number of datapoints that\n",
    "are included in each mini-batch.\n",
    "    - **epochs**: An integer that determines the number of times the training\n",
    "goes through all the datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "class FiveLayerPerceptronRegressor(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.01, batch_size=100, epochs=100, size_hidden=100):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.size_hidden = size_hidden\n",
    "\n",
    "        self.rng = np.random.default_rng(0)\n",
    "\n",
    "        self.training_losses = np.zeros(self.epochs)\n",
    "\n",
    "    def _sigmoid(self, Z):\n",
    "        return 1.0 / (1.0 + np.exp(-Z))\n",
    "\n",
    "    def _sigmoid_derivative(self, Z):\n",
    "        x = self._sigmoid(Z)\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def cost_function(self, y, y_hat):\n",
    "        return np.sum(np.square(y_hat - y)) * 1/2 \n",
    "\n",
    "    def cost_gradient(self, y, y_hat):\n",
    "        return (y_hat - y)\n",
    "\n",
    "    def _forward_propagation(self, X):\n",
    "        self.Z = []\n",
    "        self.A = []\n",
    "\n",
    "        for i in range(5):\n",
    "            self.Z.append((X @ self._W[i]))\n",
    "            self.A.append(self._sigmoid(self.Z[i]))\n",
    "            self.A[i] = np.c_[np.ones((self.A[i].shape[0],1)), self.A[i]]\n",
    "            X = self.A[i]\n",
    "            \n",
    "        self.Z.append((self.A[-1] @ self._W[-1]))\n",
    "        self.A.append(self.Z[-1])\n",
    "\n",
    "        return self.A[-1]\n",
    "\n",
    "    # function of backward propagation for regression\n",
    "    def _backward_propagation(self, X, y):\n",
    "        dA = []\n",
    "        dW = []\n",
    "        delta = []\n",
    "        \n",
    "        dA.append(self.cost_gradient(y, self.A[-1]))\n",
    "        delta.append(dA[0])\n",
    "        dW.append((self.A[-2].T @ delta[0]))\n",
    "        \n",
    "        for i in range(5, 1, -1):   \n",
    "            dA.append((delta[-1] @ self._W[i][1:,:].T))\n",
    "            delta.append(dA[-1] * self._sigmoid_derivative(self.Z[i-1]))\n",
    "            dW.append((self.A[i-2].T @ delta[-1]))\n",
    "\n",
    "        dA.append((delta[-1] @ self._W[1][1:,:].T))\n",
    "        delta.append(dA[-1] * self._sigmoid_derivative(self.Z[0]))\n",
    "        dW.append((X.T @ delta[-1]))\n",
    "\n",
    "\n",
    "        dW.reverse()\n",
    "\n",
    "        return dW\n",
    "        \n",
    "    def _weight_update(self, dW, curr):\n",
    "        for i in range(len(dW)):\n",
    "            self._W[i] -= (self.learning_rate * dW[i]) / curr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, m = X.shape\n",
    "\n",
    "        _X = np.c_[np.ones((n,1)), X]\n",
    "        y = y.to_numpy()\n",
    "        _y = y[:,np.newaxis]\n",
    "\n",
    "        self._W = []\n",
    "\n",
    "        self._W.append(np.random.randn(m+1, self.size_hidden))\n",
    "        for i in range(4):\n",
    "            self._W.append(np.random.randn(self.size_hidden+1, self.size_hidden))\n",
    "        self._W.append(np.random.randn(self.size_hidden+1, 1))\n",
    "\n",
    "        n_batches = (n + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for b in range(n_batches):\n",
    "                _X_batch = _X[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                _y_batch = _y[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                y_pred = self._forward_propagation(_X_batch)\n",
    "                curr_batch_size = _y_batch.shape[0]\n",
    "                dW = self._backward_propagation(_X_batch, _y_batch)\n",
    "                self._weight_update(dW, curr_batch_size)\n",
    "            y_pred = self._forward_propagation(_X)\n",
    "            self.training_losses[epoch] = self.cost_function(_y, y_pred)\n",
    "\n",
    "    def predict(self, X):\n",
    "        n, m = X.shape\n",
    "        _X = np.c_[np.ones((n, 1)), X]\n",
    "        \n",
    "        return self._forward_propagation(_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Train the estimator you implemented using the training set. Use the trained estimator\n",
    "to predict values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-277.88314592]\n",
      " [ -28.27488448]\n",
      " [ -78.88548826]\n",
      " ...\n",
      " [  19.74843743]\n",
      " [ 335.02842441]\n",
      " [ 192.31752127]]\n"
     ]
    }
   ],
   "source": [
    "model = FiveLayerPerceptronRegressor(epochs=100, learning_rate=0.01, batch_size=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Use the scikit-learn MLPRegressor estimator. Train it on the training test and generate\n",
    "predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-279.58906611,  -25.62985927,  -79.18778489, ...,   23.17394624,\n",
       "        321.06162727,  191.40299872])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), \\\n",
    "    learning_rate_init=0.1, activation=\"logistic\",\\\n",
    "    batch_size=100)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_mlp_pred = mlp.predict(X_test)\n",
    "y_mlp_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Compare the performance of both models using the mean squared error metric from\n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.492074485721515 13.817093577147121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_pred), mean_squared_error(y_test, y_mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Loss')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(model.training_losses)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **2)** multi layers perceptron classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the data into a pandas DataFrame, and get a scikit-learn compatible dataset. Use\n",
    "the “target” column as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "full_data_part2 = pd.read_csv(\"Part 2.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Using only half of the data\n",
    "partial_data_2 = full_data_part2.head(int(full_data_part2.shape[0]))\n",
    "\n",
    "features_2 = [x for x in partial_data_2.columns.drop(\"target\")]\n",
    "\n",
    "X_2 = partial_data_2[features_2]\n",
    "y_2 = partial_data_2[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.772441</td>\n",
       "      <td>0.360758</td>\n",
       "      <td>-2.381101</td>\n",
       "      <td>0.087570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.149460</td>\n",
       "      <td>0.622546</td>\n",
       "      <td>0.373029</td>\n",
       "      <td>0.459658</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.908792</td>\n",
       "      <td>-1.160263</td>\n",
       "      <td>-0.273645</td>\n",
       "      <td>-0.827660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.776947</td>\n",
       "      <td>0.314343</td>\n",
       "      <td>-2.262319</td>\n",
       "      <td>0.063391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.170471</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>-2.173768</td>\n",
       "      <td>-0.134220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_0    feat_1    feat_2    feat_3  target\n",
       "0 -0.772441  0.360758 -2.381101  0.087570     0.0\n",
       "1  1.149460  0.622546  0.373029  0.459658     0.0\n",
       "2 -1.908792 -1.160263 -0.273645 -0.827660     1.0\n",
       "3 -0.776947  0.314343 -2.262319  0.063391     0.0\n",
       "4 -1.170471  0.022124 -2.173768 -0.134220     0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make a 70%/30% split of the dataset for training and testing respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de treino: (7000, 4)\n",
      "Tamanho de teste: (3000, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.30, random_state=0)\n",
    "\n",
    "print(f\"Tamanho de treino: {X_train_2.shape}\")\n",
    "print(f\"Tamanho de teste: {X_test_2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using numpy, create a scikit-learn classifier that implements a multilayer perceptron\n",
    "with the following parameters:\n",
    "- Each hidden layer must have a bias unit.\n",
    "- All activations should be the sigmoid function.\n",
    "- You must use the backpropagation algorithm to calculate the derivatives.\n",
    "- Use mini-batch gradient descent to update the weights.\n",
    "- The parameters of the estimator are the following:\n",
    "    - **hidden_layers_dimensions**: A list of integers that determines the number\n",
    "and dimensionality of the hidden layers. The number of items on the list\n",
    "determine the number of hidden layers. The first element of the list (at\n",
    "index 0) is the dimensionality of the first hidden layer (connected to the\n",
    "input). The last element is the dimensionality of the hidden layer\n",
    "(connected to the output layer). The dimensionality does not include the\n",
    "bias term. The dimensionality of the input and output layers should be\n",
    "inferred from the dimensionality of the data.\n",
    "For example: A list [4,3,2] will generate 3 hidden layers with dimensions\n",
    "4, 3, and 2, respectively. If we count the bias units, the dimensions are 5,\n",
    "4, 3.\n",
    "    - **learning_rate**: A float number that determines the learning rate used for\n",
    "updating the weights in gradient descent.\n",
    "    - **batch_size**: An integer that determines the number of datapoints that\n",
    "are included in each mini-batch.\n",
    "    - **epochs**: An integer that determines the number of times the training\n",
    "goes through all the datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "# Class of a neural network for classification\n",
    "class NeuralNetClass(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hidden_layer_dimensions, learning_rate, batch_size\n",
    "                    , epochs):\n",
    "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
    "        self.size_of_hidden = len(hidden_layer_dimensions)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.training_losses = np.zeros(self.epochs)\n",
    "        self.rng = np.random.default_rng(3)\n",
    "\n",
    "    def _sigmoid(self, Z):\n",
    "        return 1.0 / (1.0 + np.exp(-Z))\n",
    "\n",
    "    def _sigmoid_derivative(self, Z):\n",
    "        x = self._sigmoid(Z)\n",
    "        return x * (1.0 - x)\n",
    "\n",
    "    def cost_function(self, y, y_hat):\n",
    "        return -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "\n",
    "    def cost_gradient(self, y, y_hat):\n",
    "        return -np.divide(y, y_hat) + np.divide(1.0 - y, 1.0 - y_hat)\n",
    "\n",
    "    def _forward_propagation(self, X):\n",
    "        self.Z = []\n",
    "        self.A = []\n",
    "\n",
    "        for i in range(self.size_of_hidden):\n",
    "            self.Z.append((X @ self._W[i]))\n",
    "            self.A.append(self._sigmoid(self.Z[i]))\n",
    "            self.A[i] = np.c_[np.ones((self.A[i].shape[0],1)), self.A[i]]\n",
    "            X = self.A[i]\n",
    "\n",
    "        self.Z.append((self.A[-1] @ self._W[-1]))\n",
    "        self.A.append(self._sigmoid(self.Z[-1]))\n",
    "\n",
    "        return self.A[-1]\n",
    "\n",
    "    def _backward_propagation(self, X, y):\n",
    "        dA = []\n",
    "        dW = []\n",
    "        dZ = []\n",
    "\n",
    "        dA.append(self.cost_gradient(y, self.A[-1]))\n",
    "        dZ.append(dA[0] * self._sigmoid_derivative(self.Z[-1]))\n",
    "        dW.append(self.A[-2].T @ dZ[0])\n",
    "\n",
    "        for i in range(self.size_of_hidden, 1, -1):\n",
    "            dA.append(dZ[-1] @ self._W[i][1:,:].T)\n",
    "            dZ.append(dA[-1] * self._sigmoid_derivative(self.Z[i-1]))\n",
    "            dW.append(self.A[i-2].T @ dZ[-1])\n",
    "        \n",
    "        dA.append(dZ[-1] @ self._W[1][1:,:].T)\n",
    "        dZ.append(dA[-1] * self._sigmoid_derivative(self.Z[0]))\n",
    "        dW.append(X.T @ dZ[-1])\n",
    "\n",
    "        dW.reverse()\n",
    "\n",
    "        return dW\n",
    "\n",
    "    def _weight_update(self, dW, curr_batch_size):\n",
    "        for i in range(len(self._W)):\n",
    "            self._W[i] -= (self.learning_rate * dW[i])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        _X = np.c_[np.ones((m, 1)), X]\n",
    "        y = y.to_numpy()\n",
    "        _y = y[:, np.newaxis]\n",
    "\n",
    "        self._W = []\n",
    "        self._W.append(self.rng.normal(size=(n+1, self.hidden_layer_dimensions[0])))\n",
    "        for i in range(1, self.size_of_hidden):\n",
    "            self._W.append(self.rng.normal(size=(self.hidden_layer_dimensions[i-1]+1, self.hidden_layer_dimensions[i])))\n",
    "        self._W.append(self.rng.normal(size=(self.hidden_layer_dimensions[-1]+1, 1)))\n",
    "\n",
    "        n_batches = (n + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for b in range(n_batches):\n",
    "                _X_batch = _X[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                _y_batch = _y[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                y_pred = self._forward_propagation(_X_batch)\n",
    "                dW = self._backward_propagation(_X_batch, _y_batch)\n",
    "                curr_batch_size = _y_batch.shape[0]\n",
    "                self._weight_update(dW, curr_batch_size)\n",
    "            y_pred = self._forward_propagation(_X)\n",
    "            self.training_losses[epoch] = self.cost_function(_y, y_pred)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        X = check_array(X)\n",
    "        n, m = X.shape\n",
    "        _X = np.c_[np.ones((n, 1)), X]\n",
    "        \n",
    "        pred_1 = self._forward_propagation(_X)\n",
    "        pred_0 = 1 - pred_1\n",
    "        return np.c_[pred_0, pred_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Train the estimator you implemented using the training set. Use the trained estimator\n",
    "to predict values for the test set.\n",
    "- During training, use the following parameters\n",
    "    - hidden_layers_dimensions = [4,4,4,4]\n",
    "    - learning_rate = 0.0001\n",
    "    - batch_size = 32\n",
    "    - epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.89      0.91      1496\n",
      "         1.0       0.89      0.94      0.91      1504\n",
      "\n",
      "    accuracy                           0.91      3000\n",
      "   macro avg       0.91      0.91      0.91      3000\n",
      "weighted avg       0.91      0.91      0.91      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model2 = NeuralNetClass(hidden_layer_dimensions=[100, 100, 100, 100, 100], learning_rate=0.0001, batch_size=1000, epochs=100)\n",
    "model2.fit(X_train_2, y_train_2)\n",
    "\n",
    "y_pred_2 = model2.predict(X_test_2)\n",
    "print(y_pred_2)\n",
    "print(classification_report(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Evaluate the trained model on the test set using the following metrics:\n",
    "- Accuracy\n",
    "- AUC-PR\n",
    "- AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.91\n",
      "PR score: 0.87\n",
      "roc auc score: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score\n",
    "acc_score = accuracy_score(y_test_2, y_pred_2)\n",
    "avr_pr_score = average_precision_score(y_test_2, y_pred_2)  \n",
    "roc_score = roc_auc_score(y_test_2, y_pred_2)   \n",
    "\n",
    "print(f\"accuracy score: {acc_score:.2}\")\n",
    "print(f\"PR score: {avr_pr_score:.2}\")\n",
    "print(f\"roc auc score: {roc_score:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) During each epoch of training, collect the loss, and make a plot with the epoch number\n",
    "in the X axis, and the loss on the Y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(model2.training_losses)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Print the confusion matrix related to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test_2, y_pred_2)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"viridis\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **3)** Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the data into a pandas DataFrame, and get a scikit-learn compatible dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "data3 = pd.read_csv(\"adult.data\", header=None, names=columns)\n",
    "\n",
    "partial_data_3 = data3.head(int(data3.shape[0])).head(1000)\n",
    "\n",
    "features_3 = [x for x in partial_data_3.columns.drop(\"income\")]\n",
    "\n",
    "X_3 = partial_data_3[features_3]\n",
    "y_3 = partial_data_3[\"income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make a 70%/30% split of the dataset for training and testing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de treino: (700, 14)\n",
      "Tamanho de teste: (300, 14)\n"
     ]
    }
   ],
   "source": [
    "# train test split of data3\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y_3, test_size=0.30, random_state=0)\n",
    "\n",
    "print(f\"Tamanho de treino: {X_train_3.shape}\")\n",
    "print(f\"Tamanho de teste: {X_test_3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "{' <=50K', ' >50K'}\n"
     ]
    }
   ],
   "source": [
    "print(y_train_3[y_train_3 == \" >50K\"].count())\n",
    "print(set(y_train_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 5}\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,1,3,5,5])\n",
    "print(set(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) An implementation of the Random Forest algorithm, as described in Section 8.2.2 of the\n",
    "Witten, James, Hastie & Tibshirani book. You should add the following options:\n",
    "- A parameter num_features for the number of predictors to consider at each split\n",
    "- A parameter num_trees to control the number of trees in the forest\n",
    "- Parameters for controlling the growth of trees, you need to implement at least\n",
    "two of the following:\n",
    "    - Maximum level of the tree\n",
    "    - Minimum number of observations in a node\n",
    "    - Stopping criterion based on the proportion of classes in the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy\n",
    "def entropy(y):\n",
    "    unique_samples = set(y.flatten())\n",
    "    entropy = 0\n",
    "    for i in unique_samples:\n",
    "        p = y[y == i].shape[0] / y.shape[0]\n",
    "        entropy -= p * np.log2(p)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def information_gain(parent, right, left):\n",
    "    entropy_parent = entropy(parent)\n",
    "    right_frac = right.shape[0] / parent.shape[0]\n",
    "    left_frac = left.shape[0] / parent.shape[0]\n",
    "    ig = entropy_parent - (right_frac * entropy(right) + left_frac * entropy(left))\n",
    "\n",
    "    return ig\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, is_leaf=None,feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "# class decision tree\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_split = 2, max_depth=100, number_of_feats=None, min_samples_quant=2):\n",
    "        self.min_split = min_split\n",
    "        self.max_depth = max_depth\n",
    "        self.number_of_feats = number_of_feats\n",
    "        self.root = None\n",
    "        self.min_samples_quant = min_samples_quant\n",
    "\n",
    "    def _majority_vote(self, y):\n",
    "        unique_samples = set(y.flatten())\n",
    "        max_count = 0\n",
    "        max_label = None\n",
    "        for i in unique_samples:\n",
    "            count = y[y == i].shape[0]\n",
    "            if count > max_count:\n",
    "                max_count = count\n",
    "                max_label = i\n",
    "        return max_label\n",
    "\n",
    "    def _find_best_split(self, X, random_feat):\n",
    "        feat_cut = None\n",
    "        threshold = None\n",
    "        best_ig = -1\n",
    "        for i in random_feat:\n",
    "            for j in set(X[:, i].flatten()):\n",
    "                # print(threshold)\n",
    "                right = X[X[:, i] > j][:,i]\n",
    "                left = X[X[:, i] <= j][:,i]\n",
    "                ig = information_gain(X[:, i], right, left)\n",
    "                if ig > best_ig:\n",
    "                    best_ig = ig\n",
    "                    feat_cut = i\n",
    "                    threshold = j\n",
    "        return feat_cut, threshold\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        m, n = X.shape\n",
    "        n_labels = X.shape[1]\n",
    "\n",
    "        criterias = (depth >= self.max_depth) or \\\n",
    "            (n_labels == self.min_samples_quant) or \\\n",
    "            (len(X) <= self.min_split)\n",
    "\n",
    "        if criterias:\n",
    "            return Node(is_leaf=True, value=self._majority_vote(y))\n",
    "\n",
    "        \n",
    "        random_feat = np.random.choice(X.shape[1], self.number_of_feats, replace=False)\n",
    "        \n",
    "        feat_cut, threshold = self._find_best_split(X, random_feat)\n",
    "        \n",
    "        \n",
    "        left = self._build_tree(X[X[:, feat_cut] <= threshold], y[X[:, feat_cut] <= threshold], depth + 1)\n",
    "        right = self._build_tree(X[X[:, feat_cut] > threshold], y[X[:, feat_cut] > threshold], depth + 1)\n",
    "        \n",
    "        return Node(is_leaf=False, feature=feat_cut, threshold=threshold, left=left, right=right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Verifica se n_feat é None \n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        if self.number_of_feats is None:\n",
    "            self.number_of_feats = X.shape[1]\n",
    "        else:\n",
    "            self.number_of_feats = min(self.number_of_feats, X.shape[1])\n",
    "        \n",
    "        self.root = self._build_tree(X, y)\n",
    "\n",
    "    def _traverse_tree(self, X, node):\n",
    "        if node.is_leaf:\n",
    "            return node.value\n",
    "        if X[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(node.left, X)\n",
    "        return self._traverse_tree(node.right, X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        ''' function to predict new dataset '''\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' function to predict a single data point '''\n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature]\n",
    "\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "        \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature), \"<=\", tree.threshold)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 177387\n",
      " left:X_2 <= 112763\n",
      "  left:X_2 <= 81145\n",
      "    left: <=50K\n",
      "    right: <=50K\n",
      "  right:X_6 <=  Farming-fishing\n",
      "    left: <=50K\n",
      "    right: <=50K\n",
      " right:X_2 <= 249609\n",
      "  left:X_6 <=  Machine-op-inspct\n",
      "    left: <=50K\n",
      "    right: <=50K\n",
      "  right:X_2 <= 304873\n",
      "    left: <=50K\n",
      "    right: <=50K\n"
     ]
    }
   ],
   "source": [
    "tree_test = DecisionTree(min_split=2, max_depth=3, number_of_feats=None, min_samples_quant=2)\n",
    "tree_test.fit(X_train_3, y_train_3)\n",
    "pred_tree = tree_test.predict(X_test_3.to_numpy())\n",
    "tree_test.print_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866666666666666"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_3, pred_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **4)** Performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Use your classifiers (multi-layer perceptron classifier and random forest).\n",
    "- Train them on the training set.\n",
    "- Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Choose any 3 classifiers from scikit-learn and repeat steps in a) for each classifier. You\n",
    "can find a list of classifiers on the scikit-learn documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. ... 1. 1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.78      0.81      1496\n",
      "         1.0       0.80      0.86      0.83      1504\n",
      "\n",
      "    accuracy                           0.82      3000\n",
      "   macro avg       0.82      0.82      0.82      3000\n",
      "weighted avg       0.82      0.82      0.82      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X_train_2, y_train_2)\n",
    "\n",
    "print(nc.predict(X_test_2))\n",
    "\n",
    "print(classification_report(y_test_2, nc.predict(X_test_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 1. 1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.87      0.88      1496\n",
      "         1.0       0.88      0.89      0.88      1504\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.88      0.88      0.88      3000\n",
      "weighted avg       0.88      0.88      0.88      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree_class = tree.DecisionTreeClassifier()\n",
    "tree_class = tree_class.fit(X_train_2, y_train_2)\n",
    "\n",
    "print(tree_class.predict(X_test_2))\n",
    "\n",
    "print(classification_report(y_test_2, tree_class.predict(X_test_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. ... 1. 1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.73      0.77      1496\n",
      "         1.0       0.76      0.84      0.80      1504\n",
      "\n",
      "    accuracy                           0.79      3000\n",
      "   macro avg       0.79      0.79      0.78      3000\n",
      "weighted avg       0.79      0.79      0.78      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian = gaussian.fit(X_train_2, y_train_2)\n",
    "\n",
    "print(gaussian.predict(X_test_2))\n",
    "\n",
    "print(classification_report(y_test_2, gaussian.predict(X_test_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) You will have obtained 5 sets of predictions from all the models you trained. Use these\n",
    "predictions and the labels from the test set to calculate the performance of each model\n",
    "using the following performance metrics:\n",
    "- Precision\n",
    "- Recall\n",
    "- AUC-ROC\n",
    "- AUC-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________Nearest Centroid______________\n",
      "\n",
      "PR score: 0.76\n",
      "ROC score: 0.82\n",
      "\n",
      "_____________Decision Tree______________\n",
      "\n",
      "PR score: 0.83\n",
      "ROC score: 0.88\n",
      "\n",
      "_____________Naive Bayes______________\n",
      "\n",
      "PR score: 0.72\n",
      "ROC score: 0.79\n",
      "\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "models = [nc, tree_class, gaussian]\n",
    "names = [\"Nearest Centroid\", \"Decision Tree\", \"Naive Bayes\"]\n",
    "\n",
    "\n",
    "for i in range(len(models)):\n",
    "    y_pred_2 = models[i].predict(X_test_2)\n",
    "    print(f\"_____________{names[i]}______________\\n\")\n",
    "    print(f\"PR score: {average_precision_score(y_test_2, y_pred_2):.2}\")\n",
    "    print(f\"ROC score: {roc_auc_score(y_test_2, y_pred_2):.2}\")\n",
    "    print()\n",
    "print(\"______________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create a comparison report. Your code will:\n",
    "- Print a table with values of the performance metric (columns) for each model\n",
    "(rows) on the test set.\n",
    "- Make a single figure containing 2 subplots. In the first subplot, you will plot the\n",
    "ROC curves for each model. In the second subplot, you will plot the PR curves for\n",
    "each model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2b3411e9fd7ba1867b3fa0e3f5ed61c5273131a2f49fe4d5db3319f94defb8e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
