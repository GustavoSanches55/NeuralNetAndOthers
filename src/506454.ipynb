{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import permutations, combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **1)** Five layer perceptron regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the data into a pandas DataFrame, and get a scikit-learn compatible dataset. Use\n",
    "the “target” column as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "full_data_part1 = pd.read_csv(\"Part 1.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Using only half of the data\n",
    "partial_data = full_data_part1.head(int(full_data_part1.shape[0]/2))\n",
    "\n",
    "features = [x for x in partial_data.columns.drop(\"target\")]\n",
    "\n",
    "X = partial_data[features]\n",
    "y = partial_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314826</td>\n",
       "      <td>0.876050</td>\n",
       "      <td>-0.685288</td>\n",
       "      <td>0.604524</td>\n",
       "      <td>-0.868619</td>\n",
       "      <td>-0.671283</td>\n",
       "      <td>-59.177636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662332</td>\n",
       "      <td>0.745420</td>\n",
       "      <td>-0.423713</td>\n",
       "      <td>0.179228</td>\n",
       "      <td>-1.349615</td>\n",
       "      <td>0.355827</td>\n",
       "      <td>-11.643998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.448170</td>\n",
       "      <td>0.065115</td>\n",
       "      <td>0.107046</td>\n",
       "      <td>0.459968</td>\n",
       "      <td>1.302039</td>\n",
       "      <td>-0.758131</td>\n",
       "      <td>35.562439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.199397</td>\n",
       "      <td>-1.109276</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.916933</td>\n",
       "      <td>-0.325098</td>\n",
       "      <td>-0.655460</td>\n",
       "      <td>-18.147836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.066389</td>\n",
       "      <td>1.762515</td>\n",
       "      <td>0.560241</td>\n",
       "      <td>-1.308726</td>\n",
       "      <td>-0.631064</td>\n",
       "      <td>-0.038181</td>\n",
       "      <td>-42.328718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_0    feat_1    feat_2    feat_3    feat_4    feat_5     target\n",
       "0  0.314826  0.876050 -0.685288  0.604524 -0.868619 -0.671283 -59.177636\n",
       "1  0.662332  0.745420 -0.423713  0.179228 -1.349615  0.355827 -11.643998\n",
       "2 -0.448170  0.065115  0.107046  0.459968  1.302039 -0.758131  35.562439\n",
       "3  1.199397 -1.109276 -0.003139 -0.916933 -0.325098 -0.655460 -18.147836\n",
       "4 -0.066389  1.762515  0.560241 -1.308726 -0.631064 -0.038181 -42.328718"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make a 70%/30% split of the dataset for training and testing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de treino: (3500, 6)\n",
      "Tamanho de teste: (1500, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print(f\"Tamanho de treino: {X_train.shape}\")\n",
    "print(f\"Tamanho de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using numpy, create a scikit-learn regressor that implements a multilayer perceptron\n",
    "architecture with 5 hidden layers.\n",
    "- The dimensionality of each layer is your decision.\n",
    "- Each hidden layer must have a bias unit.\n",
    "- All activations should be the sigmoid function.\n",
    "- You must use the backpropagation algorithm to calculate the derivatives.\n",
    "- Use mini-batch gradient descent to update the weights.\n",
    "- The parameters of the estimator are the following:\n",
    "    - **learning_rate:** A float number that determines the learning rate used for\n",
    "updating the weights on the update step of the gradient descent.\n",
    "    - **batch_size**: An integer that determines the number of datapoints that\n",
    "are included in each mini-batch.\n",
    "    - **epochs**: An integer that determines the number of times the training\n",
    "goes through all the datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "class FiveLayerPerceptronRegressor(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.01, batch_size=100, epochs=100, size_hidden=100):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.size_hidden = size_hidden\n",
    "\n",
    "        self.rng = np.random.default_rng(0)\n",
    "\n",
    "        self.training_losses = np.zeros(self.epochs)\n",
    "\n",
    "    def _sigmoid(self, Z):\n",
    "        return 1.0 / (1.0 + np.exp(-Z))\n",
    "\n",
    "    def _sigmoid_derivative(self, Z):\n",
    "        x = self._sigmoid(Z)\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def cost_function(self, y, y_hat):\n",
    "        return np.sum(np.square(y_hat - y)) * 1/2 \n",
    "\n",
    "    def cost_gradient(self, y, y_hat):\n",
    "        return (y_hat - y)\n",
    "\n",
    "    def _forward_propagation(self, X):\n",
    "        self.Z = []\n",
    "        self.A = []\n",
    "\n",
    "        for i in range(5):\n",
    "            self.Z.append((X @ self._W[i]))\n",
    "            self.A.append(self._sigmoid(self.Z[i]))\n",
    "            self.A[i] = np.c_[np.ones((self.A[i].shape[0],1)), self.A[i]]\n",
    "            X = self.A[i]\n",
    "            \n",
    "        self.Z.append((self.A[-1] @ self._W[-1]))\n",
    "        self.A.append(self.Z[-1])\n",
    "\n",
    "        return self.A[-1]\n",
    "\n",
    "    # function of backward propagation for regression\n",
    "    def _backward_propagation(self, X, y):\n",
    "        dA = []\n",
    "        dW = []\n",
    "        delta = []\n",
    "        \n",
    "        dA.append(self.cost_gradient(y, self.A[-1]))\n",
    "        delta.append(dA[0])\n",
    "        dW.append((self.A[-2].T @ delta[0]))\n",
    "        \n",
    "        for i in range(5, 1, -1):   \n",
    "            dA.append((delta[-1] @ self._W[i][1:,:].T))\n",
    "            delta.append(dA[-1] * self._sigmoid_derivative(self.Z[i-1]))\n",
    "            dW.append((self.A[i-2].T @ delta[-1]))\n",
    "\n",
    "        dA.append((delta[-1] @ self._W[1][1:,:].T))\n",
    "        delta.append(dA[-1] * self._sigmoid_derivative(self.Z[0]))\n",
    "        dW.append((X.T @ delta[-1]))\n",
    "\n",
    "\n",
    "        dW.reverse()\n",
    "\n",
    "        return dW\n",
    "        \n",
    "    def _weight_update(self, dW, curr):\n",
    "        for i in range(len(dW)):\n",
    "            self._W[i] -= (self.learning_rate * dW[i]) / curr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, m = X.shape\n",
    "\n",
    "        _X = np.c_[np.ones((n,1)), X]\n",
    "        y = y.to_numpy()\n",
    "        _y = y[:,np.newaxis]\n",
    "\n",
    "        self._W = []\n",
    "\n",
    "        self._W.append(np.random.randn(m+1, self.size_hidden))\n",
    "        for i in range(4):\n",
    "            self._W.append(np.random.randn(self.size_hidden+1, self.size_hidden))\n",
    "        self._W.append(np.random.randn(self.size_hidden+1, 1))\n",
    "\n",
    "        n_batches = (n + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for b in range(n_batches):\n",
    "                _X_batch = _X[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                _y_batch = _y[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                y_pred = self._forward_propagation(_X_batch)\n",
    "                curr_batch_size = _y_batch.shape[0]\n",
    "                dW = self._backward_propagation(_X_batch, _y_batch)\n",
    "                self._weight_update(dW, curr_batch_size)\n",
    "            y_pred = self._forward_propagation(_X)\n",
    "            self.training_losses[epoch] = self.cost_function(_y, y_pred)\n",
    "\n",
    "    def predict(self, X):\n",
    "        n, m = X.shape\n",
    "        _X = np.c_[np.ones((n, 1)), X]\n",
    "        \n",
    "        return self._forward_propagation(_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Train the estimator you implemented using the training set. Use the trained estimator\n",
    "to predict values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-280.93209243]\n",
      " [ -23.87860032]\n",
      " [ -75.86249576]\n",
      " ...\n",
      " [  25.07713113]\n",
      " [ 328.01662631]\n",
      " [ 194.89680477]]\n"
     ]
    }
   ],
   "source": [
    "model = FiveLayerPerceptronRegressor(epochs=100, learning_rate=0.01, batch_size=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Use the scikit-learn MLPRegressor estimator. Train it on the training test and generate\n",
    "predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-278.78582288,  -25.84546532,  -77.58219429, ...,   20.75654089,\n",
       "        333.62770072,  191.99418421])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), \\\n",
    "    learning_rate_init=0.1, activation=\"logistic\",\\\n",
    "    batch_size=100)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_mlp_pred = mlp.predict(X_test)\n",
    "y_mlp_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Compare the performance of both models using the mean squared error metric from\n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.993113780199046 5.492905920976894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_pred), mean_squared_error(y_test, y_mlp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **2)** multi layers perceptron classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the data into a pandas DataFrame, and get a scikit-learn compatible dataset. Use\n",
    "the “target” column as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "full_data_part2 = pd.read_csv(\"Part 2.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Using only half of the data\n",
    "partial_data_2 = full_data_part2.head(int(full_data_part2.shape[0]))\n",
    "\n",
    "features_2 = [x for x in partial_data_2.columns.drop(\"target\")]\n",
    "\n",
    "X_2 = partial_data_2[features_2]\n",
    "y_2 = partial_data_2[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.772441</td>\n",
       "      <td>0.360758</td>\n",
       "      <td>-2.381101</td>\n",
       "      <td>0.087570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.149460</td>\n",
       "      <td>0.622546</td>\n",
       "      <td>0.373029</td>\n",
       "      <td>0.459658</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.908792</td>\n",
       "      <td>-1.160263</td>\n",
       "      <td>-0.273645</td>\n",
       "      <td>-0.827660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.776947</td>\n",
       "      <td>0.314343</td>\n",
       "      <td>-2.262319</td>\n",
       "      <td>0.063391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.170471</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>-2.173768</td>\n",
       "      <td>-0.134220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_0    feat_1    feat_2    feat_3  target\n",
       "0 -0.772441  0.360758 -2.381101  0.087570     0.0\n",
       "1  1.149460  0.622546  0.373029  0.459658     0.0\n",
       "2 -1.908792 -1.160263 -0.273645 -0.827660     1.0\n",
       "3 -0.776947  0.314343 -2.262319  0.063391     0.0\n",
       "4 -1.170471  0.022124 -2.173768 -0.134220     0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make a 70%/30% split of the dataset for training and testing respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de treino: (7000, 4)\n",
      "Tamanho de teste: (3000, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.30, random_state=0)\n",
    "\n",
    "print(f\"Tamanho de treino: {X_train_2.shape}\")\n",
    "print(f\"Tamanho de teste: {X_test_2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using numpy, create a scikit-learn classifier that implements a multilayer perceptron\n",
    "with the following parameters:\n",
    "- Each hidden layer must have a bias unit.\n",
    "- All activations should be the sigmoid function.\n",
    "- You must use the backpropagation algorithm to calculate the derivatives.\n",
    "- Use mini-batch gradient descent to update the weights.\n",
    "- The parameters of the estimator are the following:\n",
    "    - **hidden_layers_dimensions**: A list of integers that determines the number\n",
    "and dimensionality of the hidden layers. The number of items on the list\n",
    "determine the number of hidden layers. The first element of the list (at\n",
    "index 0) is the dimensionality of the first hidden layer (connected to the\n",
    "input). The last element is the dimensionality of the hidden layer\n",
    "(connected to the output layer). The dimensionality does not include the\n",
    "bias term. The dimensionality of the input and output layers should be\n",
    "inferred from the dimensionality of the data.\n",
    "For example: A list [4,3,2] will generate 3 hidden layers with dimensions\n",
    "4, 3, and 2, respectively. If we count the bias units, the dimensions are 5,\n",
    "4, 3.\n",
    "    - **learning_rate**: A float number that determines the learning rate used for\n",
    "updating the weights in gradient descent.\n",
    "    - **batch_size**: An integer that determines the number of datapoints that\n",
    "are included in each mini-batch.\n",
    "    - **epochs**: An integer that determines the number of times the training\n",
    "goes through all the datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "# Class of a neural network for classification\n",
    "class NeuralNetClass(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hidden_layer_dimensions, learning_rate, batch_size\n",
    "                    , epochs):\n",
    "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
    "        self.size_of_hidden = len(hidden_layer_dimensions)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.training_losses = np.zeros(self.epochs)\n",
    "        self.rng = np.random.default_rng(0)\n",
    "\n",
    "    def _sigmoid(self, Z):\n",
    "        return 1.0 / (1.0 + np.exp(-Z))\n",
    "\n",
    "    def _sigmoid_derivative(self, Z):\n",
    "        return self._sigmoid(Z) * (1.0 - self._sigmoid(Z))\n",
    "\n",
    "    def cost_function(self, y, y_hat):\n",
    "        return -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "\n",
    "    def cost_gradient(self, y, y_hat):\n",
    "        return -np.divide(y, y_hat) + np.divide(1.0 - y, 1.0 - y_hat)\n",
    "\n",
    "    def _forward_propagation(self, X):\n",
    "        self.Z = []\n",
    "        self.A = []\n",
    "\n",
    "        for i in range(self.size_of_hidden):\n",
    "            self.Z.append(np.dot(X, self._W[i]))\n",
    "            self.A.append(self._sigmoid(self.Z[i]))\n",
    "            self.A[i] = np.c_[np.ones((self.A[i].shape[0],1)), self.A[i]]\n",
    "            X = self.A[i]\n",
    "\n",
    "        self.Z.append(np.dot(self.A[-1], self._W[-1]))\n",
    "        self.A.append(self._sigmoid(self.Z[-1]))\n",
    "\n",
    "        return self.A[-1]\n",
    "        \n",
    "\n",
    "    def _backward_propagation(self, X, y):\n",
    "        dA = []\n",
    "        dW = []\n",
    "        dZ = []\n",
    "\n",
    "        dA.append(self.cost_gradient(y, self.A[-1]))\n",
    "        dZ.append(dA[0] * self._sigmoid_derivative(self.Z[-1]))\n",
    "        dW.append(self.A[-2].T @ dZ[0])\n",
    "\n",
    "        for i in range(self.size_of_hidden, 1, -1):\n",
    "            dA.append(dZ[-1] @ self._W[i][1:,:].T)\n",
    "            dZ.append(dA[-1] * self._sigmoid_derivative(self.Z[i-1]))\n",
    "            dW.append(self.A[i-2].T @ dZ[-1])\n",
    "        \n",
    "        dA.append(dZ[-1] @ self._W[1][1:,:].T)\n",
    "        dZ.append(dA[-1] * self._sigmoid_derivative(self.Z[0]))\n",
    "        dW.append(X.T @ dZ[-1])\n",
    "\n",
    "        dW.reverse()\n",
    "\n",
    "        return dW\n",
    "\n",
    "    def _weight_update(self, dW, curr_batch_size):\n",
    "        for i in range(self.size_of_hidden):\n",
    "            self._W[i] -= (dW[i])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        _X = np.c_[np.ones((m, 1)), X]\n",
    "        y = y.to_numpy()\n",
    "        _y = y[:, np.newaxis]\n",
    "\n",
    "        self._W = []\n",
    "        self._W.append(self.rng.normal(size=(n+1, self.hidden_layer_dimensions[0])))\n",
    "        for i in range(1, self.size_of_hidden):\n",
    "            self._W.append(self.rng.normal(size=(self.hidden_layer_dimensions[i-1]+1, self.hidden_layer_dimensions[i])))\n",
    "        self._W.append(self.rng.normal(size=(self.hidden_layer_dimensions[-1]+1, 1)))\n",
    "\n",
    "        n_batches = (n + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for b in range(n_batches):\n",
    "                _X_batch = _X[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                _y_batch = _y[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                y_pred = self._forward_propagation(_X_batch)\n",
    "                dW = self._backward_propagation(_X_batch, _y_batch)\n",
    "                curr_batch_size = _y_batch.shape[0]\n",
    "                self._weight_update(dW, curr_batch_size)\n",
    "            y_pred = self._forward_propagation(_X)\n",
    "            self.training_losses[epoch] = self.cost_function(_y, y_pred)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        X = check_array(X)\n",
    "        n, m = X.shape\n",
    "        _X = np.c_[np.ones((n, 1)), X]\n",
    "        \n",
    "        pred_1 = self._forward_propagation(_X)\n",
    "        pred_0 = 1 - pred_1\n",
    "        return np.c_[pred_0, pred_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Train the estimator you implemented using the training set. Use the trained estimator\n",
    "to predict values for the test set.\n",
    "- During training, use the following parameters\n",
    "    - hidden_layers_dimensions = [4,4,4,4]\n",
    "    - learning_rate = 0.0001\n",
    "    - batch_size = 32\n",
    "    - epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.84      0.83      1496\n",
      "         1.0       0.84      0.82      0.83      1504\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.83      0.83      0.83      3000\n",
      "weighted avg       0.83      0.83      0.83      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = NeuralNetClass(hidden_layer_dimensions=[4, 4, 4, 4], learning_rate=0.0001, batch_size=32, epochs=100)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "\n",
    "y_pred_2 = model.predict(X_test_2)\n",
    "print(classification_report(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Evaluate the trained model on the test set using the following metrics:\n",
    "- Accuracy\n",
    "- AUC-PR\n",
    "- AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.829\n",
      "PR score: 0.78\n",
      "roc auc score: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score, average_precision_score\n",
    "acc_score = accuracy_score(y_test_2, y_pred_2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_2, y_pred_2, pos_label=1)\n",
    "avr_pr_score = average_precision_score(y_test_2, y_pred_2)  \n",
    "roc_score = roc_auc_score(y_test_2, y_pred_2)   \n",
    "\n",
    "print(f\"accuracy score: {acc_score}\")\n",
    "print(f\"PR score: {avr_pr_score:.2}\")\n",
    "print(f\"roc auc score: {roc_score:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) During each epoch of training, collect the loss, and make a plot with the epoch number\n",
    "in the X axis, and the loss on the Y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(model.training_losses)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Print the confusion matrix related to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test_2, y_pred_2)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **3)** Random forest"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2b3411e9fd7ba1867b3fa0e3f5ed61c5273131a2f49fe4d5db3319f94defb8e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
